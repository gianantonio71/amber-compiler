//## REPLACE ALL THE unused_var, unused_var_X

// RIGHT NOW NAMED PARAMETERS ARE INCLUDED IN THE LIST OF LIVE VAR.
// THAT'S WRONG, THEY ARE JUST LIKE EXTERNAL VARS, THEY ARE ALWAYS LIVE


BoolProcDef add_ref_counting(BoolProcDef proc_def) = proc_def;


// ObjProcDef add_ref_counting(ObjProcDef proc_def) = proc_def;
ObjProcDef add_ref_counting(ObjProcDef proc_def) =
  obj_proc_def(
    proc_def.name,
    proc_def.params,
    proc_def.named_args,
    nonempty(add_ref_counting(proc_def.body)),
    proc_def.cached
  );


Block add_ref_counting(Block block) =
  block(
    name:               block.name,
    inputs:             block.inputs,
    outputs:            block.outputs,
    memb_vars:          block.memb_vars,
    nested_auto_vars:   block.nested_auto_vars,
    init_code:          safe_add_ref_counting(block.init_code),
    update_code:        safe_add_ref_counting(block.update_code),
    cleanup_code:       block.cleanup_code,
    queue_update_code:  block.queue_update_code,
    methods_code:       (n => safe_add_ref_counting(is) : is @ n <- block.methods_code),
    const_data:         block.const_data,
    time_rules_count:   block.time_rules_count
  );

////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////

// <[]> add_ref_counting(<[]>) = []; //## THIS DOESN'T WORK BECAUSE OF THAT BUG IN THE TYPECHECKER
[Instr] safe_add_ref_counting([Instr] instrs) = if instrs != [] then add_ref_counting(instrs) else [];

[Instr^] add_ref_counting([Instr^] instrs)
{
  leaf_nodes, code_tree = build_root_code_graph(instrs);
  flow_map = build_flow_map(code_tree, leaf_nodes);
  no_end_node_flow_map = [[n : n <- ns, n != end_node] : ns <- flow_map];
  rev_flow_map = reverse_flow_map(no_end_node_flow_map);
  live_vars_before_map, live_vars_after_map = build_live_vars_maps(leaf_nodes, no_end_node_flow_map);
  // ref_live_vars_before_map, ref_live_vars_after_map = ref_build_live_vars_maps(leaf_nodes, flow_map);
  entry_vars_states = entry_vars_states(leaf_nodes, no_end_node_flow_map, live_vars_after_map);
  // ref_entry_vars_states = ref_entry_vars_states(leaf_nodes, flow_map, live_vars_after_map);
  assert none([{v : v <- lvs, not is_initialized(vs, v)} != {} : lvs, vs <- zip(live_vars_before_map, entry_vars_states)]);
  let (flow_map=flow_map, live_vars_after_map=live_vars_after_map, entry_vars_states=entry_vars_states)
    rc_nodes = [add_ref_counting(n, i) : n @ i <- leaf_nodes];
  ;
  return ref_count_closures(nonempty(reconstruct(code_tree, rc_nodes)));
}

////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////

// We need to calculate a target variables state before each statement.
// Once we have one, we can decide what reference counting instructions
// We need to insert when going from one state to the next.

// This variable state depends on the release strategy. What are the
// alternatives?

//   - Greedy release: we release variables as soon as they are not needed anymore.
//     + memory is released as soon as possible
//     + the reference count on an object is always as low as can be,
//       and that can help with functional updates
//     + when a path forks, we end up doing a common release just once before the fork

//   - Lazy release: we release variables at the last possible chance to do so.
//     + when multiple code paths converge to a single node, we can do a common
//       release just once
//     + no need to release memory before a terminate statement. (NOT SURE HERE...)

// Let's say we go with the lazy release strategy.

[VarsState] entry_vars_states([NodeInfo] leaf_nodes, [[Nat]] flow_map, [TrkVar*] live_vars_after_map)
{
  len = length(leaf_nodes);

  rev_flow_map = reverse_flow_map(flow_map);
  fwd_nodes_map = [{n : n <- ns, n < i} : ns @ i <- rev_flow_map];

  entry_states = [blank_vars_state];
  for (i = 1..len)
    fwd_nodes = fwd_nodes_map[i];
    fwd_states = {exit_vars_state_only(leaf_nodes[n], entry_states[n], live_vars_after_map[n]) : n <- fwd_nodes};
    entry_states = [entry_states | reconcile(fwd_states)];
  ;

  exit_states = [exit_vars_state_only(leaf_nodes[i], entry_state, live_vars_after_map[i]) : entry_state @ i <- entry_states];

  updated_map = len * [true];
  while (at_least_one(updated_map))
    new_entry_states = [blank_vars_state];
    new_exit_states = [exit_states[0]];
    new_updated_map = [false];
    for (i = 1..len)
      nodes = rev_flow_map[i];
      if ((? n <- nodes : if n < i then new_updated_map[n] else updated_map[n]))
        states = {if n < i then new_exit_states[n] else exit_states[n] : n <- nodes};
        new_entry_state = reconcile(states);
        new_exit_state = exit_vars_state_only(leaf_nodes[i], new_entry_state, live_vars_after_map[i]);
        updated = new_entry_state != entry_states[i];
      else
        new_entry_state = entry_states[i];
        new_exit_state = exit_states[i];
        updated = false;
      ;
      new_entry_states = [new_entry_states | new_entry_state];
      new_exit_states = [new_exit_states | new_exit_state];
      new_updated_map = [new_updated_map | updated];
    ;
    entry_states = new_entry_states;
    exit_states = new_exit_states;
    updated_map = new_updated_map;
  ;

  return entry_states;
}


// [VarsState] ref_entry_vars_states([NodeInfo] leaf_nodes, [[Nat]] flow_map, [TrkVar*] live_vars_after_map)
// {
//   len = length(leaf_nodes);

//   rev_flow_map = reverse_flow_map(flow_map);
//   fwd_nodes_map = [{n : n <- ns, n < i} : ns @ i <- rev_flow_map];

//   entry_states = [blank_vars_state];
//   for (i = 1..len)
//     fwd_nodes = fwd_nodes_map[i];
//     fwd_states = {exit_vars_state_only(leaf_nodes[n], entry_states[n], live_vars_after_map[n]) : n <- fwd_nodes};
//     entry_states = [entry_states | reconcile(fwd_states)];
//   ;

//   loop
//     new_entry_states = [blank_vars_state];
//     for (i = 1..len)
//       nodes = rev_flow_map[i];
//       states = {exit_vars_state_only(leaf_nodes[n], entry_states[n], live_vars_after_map[n]) : n <- nodes};
//       new_entry_states = [new_entry_states | reconcile(states)];
//     ;
//     break if new_entry_states == entry_states;
//     entry_states = new_entry_states;
//   ;

//   return entry_states;
// }

////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////

using [[NodeId]] flow_map, [TrkVar*] live_vars_after_map, [VarsState] entry_vars_states
{
  RCNodeInfo add_ref_counting(NodeInfo info, Nat idx)
  {
    entry_state = entry_vars_states[idx];
    exit_state, pre_instrs, post_instrs = exit_vars_state(info, entry_state, live_vars_after_map[idx]);
    return add_ref_counting(info, flow_map[idx], entry_state, exit_state, pre_instrs, post_instrs);
  }


  RCNodeInfo add_ref_counting(NodeInfo info, [NodeId] next_nodes, VarsState entry_state, VarsState exit_state, [Instr] pre_instrs, [Instr] post_instrs):
    std_node(terminate)                     = std_node([terminate]),
    std_node(ret_val(e?))                   = {assert post_instrs == []; return rc_ret_node(e, entry_state, pre_instrs);},
    std_node(<break_loop, exit_block> i?)   = { assert pre_instrs == [] and post_instrs == [];
                                                return rc_break_or_exit_node(i, only_item(next_nodes), exit_state);
                                              },
    std_node(i?)                            = rc_std_node(i, only_item(next_nodes), exit_state, pre_instrs, post_instrs),
    branch_node(c?)                         = { assert pre_instrs == [] and post_instrs == [];
                                                fail if not next_nodes :: (NodeId, NodeId);
                                                return rc_branch_node(c, left(next_nodes), right(next_nodes), exit_state);
                                              },
    switch_node(v?)                         = { assert pre_instrs == [] and post_instrs == [];
                                                return rc_switch_node(v, nonempty(next_nodes), exit_state);
                                              },
    set_cls_par_node()                      = { assert pre_instrs == [] and post_instrs == [];
                                                return rc_set_cls_par_node(info.var, info.cls, only_item(next_nodes), exit_state);
                                              };


  RCNodeInfo rc_ret_node(<AtomicExpr, AtomicBoolExpr> expr, VarsState entry_state, [Instr] pre_instrs) //## THE LAST PARAMETER SHOULD BE REMOVED BECAUSE IT'S RECALCULATED. IT IS ONLY USED FOR AN ASSERTION
  {
    state, unused_var = swallow_var(entry_state, maybe_var(expr), {});
    assert pre_instrs == unused_var;
    pre_instrs_2 = gen_state_switch_code(state, blank_vars_state);
    return std_node(pre_instrs & pre_instrs_2 & [ret_val(expr)]);
  }


  RCNodeInfo rc_break_or_exit_node(Instr instr, NodeId next_node, VarsState exit_state)
  {
    next_node_entry_state = entry_vars_state(next_node);
    state_switch_code = gen_state_switch_code(exit_state, next_node_entry_state);
    return std_node([state_switch_code | instr]);
  }


  RCNodeInfo rc_std_node(Instr instr, NodeId next_node, VarsState exit_state, [Instr] pre_instrs, [Instr] post_instrs)
  {
    next_node_entry_state = entry_vars_state(next_node);
    post_instrs_2 = gen_state_switch_code(exit_state, next_node_entry_state);
    return std_node(pre_instrs & [instr] & post_instrs & post_instrs_2);
  }


  RCNodeInfo rc_branch_node(BoolExpr cond, NodeId if_next_node, NodeId then_next_node, VarsState exit_state)
  {
    if_branch_entry_state = entry_vars_state(if_next_node);
    then_branch_entry_state = entry_vars_state(then_next_node);
    if_branch_post_instrs = gen_state_switch_code(exit_state, if_branch_entry_state);
    then_branch_post_instrs = gen_state_switch_code(exit_state, then_branch_entry_state);
    return branch_node(cond, if_branch_post_instrs, then_branch_post_instrs);
  }


  RCNodeInfo rc_switch_node(IntExpr idx, [NodeId^] next_nodes, VarsState exit_state)
  {
    case_post_instrs = [gen_state_switch_code(exit_state, entry_vars_state(n)) : n <- next_nodes];
    return rc_switch_node(idx, case_post_instrs);
  }


  RCNodeInfo rc_set_cls_par_node(NamedArg var, BoundCls cls, NodeId next_node, VarsState exit_state)
  {
    next_node_entry_state = entry_vars_state(next_node);
    post_instrs = gen_state_switch_code(exit_state, next_node_entry_state);
    return set_cls_par_node(var, cls, post_instrs);
  }
}


using [VarsState] entry_vars_states
{
  VarsState entry_vars_state(NodeId next_node) =
    if next_node == end_node
      then blank_vars_state
      else entry_vars_states[next_node];
}

////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////

<[]>     ref_count_closures(<[]>)             = [];
[Instr^] ref_count_closures([Instr^] instrs)  = [ref_count_closures_single_instruction(i) : i <- instrs];


Instr ref_count_closures_single_instruction(Instr instr):
  call_proc()         = call_proc(var: instr.var if instr.var?, name: instr.name, params: [ref_count_closure(p) : p <- instr.params]),
  branch()            = branch(
                          instr.cond,
                          ref_count_closures(instr.when_true),
                          ref_count_closures(instr.when_false)
                        ),
  repeat(is?)         = repeat(nonempty(ref_count_closures(is))),
  execute_block(is?)  = execute_block(nonempty(ref_count_closures(is))),
  cls_scope()         = cls_scope(instr.var, ref_count_closure(instr.bound_cls), nonempty(ref_count_closures(instr.body))),
  _                   = instr;


AtomicExpr ref_count_closure(AtomicExpr expr) = expr; //## NOT THE BEST NAME IN THIS CASE...

BoundCls ref_count_closure(BoundCls cls):
  ClsVar        = cls,
  bound_cls()   = bound_cls(cls_def(cls.cls.arity, add_ref_counting(cls.cls.body)), cls.env);
